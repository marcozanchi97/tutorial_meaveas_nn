{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZObugkP4Rg5XbpUHuQBSL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IOE6cIqWJX1f"},"outputs":[],"source":["import copy\n","import pickle\n","from pathlib import Path\n","import warnings\n","from datetime import datetime\n","import sys\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.stats import linregress\n","from scipy.stats import mannwhitneyu\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","source":["#from google.colab import drive\n","#drive.mount('/content/drive', force_remount=True)\n","\n","!git clone https://github.com/marcozanchi97/tutorial_meaveas_nn.git"],"metadata":{"id":"LcEsRThpJhZv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["USER_PATH = 'tutorial_meaveas_nn/'\n","DATA_PATH = USER_PATH + 'data/'"],"metadata":{"id":"t1h3kdSwJjN4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_pickle(DATA_PATH + 'data_input_ml_era5_2018_2023.p')\n","\n","df['date'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n","\n","# Check that the dataset does not have holes\n","start_date = df['date'].min()\n","end_date = df['date'].max()\n","reference_dates = pd.date_range(start=start_date, end=end_date, freq='H')\n","is_missing_dates = ~reference_dates.isin(df['date'])\n","assert not is_missing_dates.any(), \"There are missing dates in the DataFrame.\"\n","\n","print(start_date, end_date)\n","df.head()"],"metadata":{"id":"KacC_0jPJ8SQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#spit data into train, validation and test sets\n","\n","df_train = df[df.date < '2021/01/01']\n","df_val = df[(df.date >= '2021/01/01') & (df.date < '2022/01/01')]\n","df_test = df[df.date >= '2022/01/01']"],"metadata":{"id":"4Fg5B2b0J8VY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#normalize data according to mean and std of train set\n","\n","columns_to_normalize = ['Wind speed', 'Wind direction','Temperature', 'Direct shortwave radiation','Diffuse shortwave radiation',\n","                        'Total precipitation', 'Humidity'\n","                       ]\n","\n","# Initialize dictionaries to store the mean and std for each column\n","norm_means = {}\n","norm_stds = {}\n","\n","# Normalize df_train and save the mean and std\n","for column in columns_to_normalize:\n","    norm_means[column] = df_train[column].mean()\n","    norm_stds[column] = df_train[column].std()\n","    df_train.loc[:,column] = (df_train[column] - norm_means[column]) / norm_stds[column]\n","\n","# Normalize df_val and df_test using the mean and std from df_train\n","for column in columns_to_normalize:\n","    df_val.loc[:,column] = (df_val[column] - norm_means[column]) / norm_stds[column]\n","    df_test.loc[:,column] = (df_test[column] - norm_means[column]) / norm_stds[column]"],"metadata":{"id":"bW3bnMGQKV_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create (input,output) examples\n","\n","def get_data_from_df(df, columns_list, target_name, input_len, prediction_len, shuffle=False, seed_value=None):\n","    data = df[columns_list].values\n","    target = df[target_name].values\n","    X, y = [], []\n","\n","    for time_idx in range(len(df) - input_len - prediction_len):\n","        X.append(data[time_idx:time_idx+input_len])\n","        y.append(target[time_idx+input_len:time_idx+input_len+prediction_len])\n","\n","    X, y = np.array(X), np.array(y)\n","\n","    if shuffle:\n","        rng = np.random.default_rng(seed_value)\n","        shuffled_indices = rng.permutation(len(X))\n","        X, y = X[shuffled_indices], y[shuffled_indices]\n","    return X, y\n","\n","# Constants\n","PREDICTION_LENGTH = 24\n","INPUT_LENGTH = 72\n","SEED = 123\n","COLUMNS_LIST = ['Temperature', 'Wind speed', 'Wind direction', 'Direct shortwave radiation',\n","                'Diffuse shortwave radiation', 'Total precipitation', 'Humidity']\n","TARGET_NAME = ['Temperature']\n","\n","# get data examples\n","X_train, y_train = get_data_from_df(df_train, COLUMNS_LIST, TARGET_NAME, INPUT_LENGTH, PREDICTION_LENGTH,shuffle=True, seed_value=SEED)\n","X_val, y_val = get_data_from_df(df_val, COLUMNS_LIST, TARGET_NAME, INPUT_LENGTH, PREDICTION_LENGTH,shuffle=True, seed_value=SEED)\n","X_test, y_test = get_data_from_df(df_test, COLUMNS_LIST, TARGET_NAME, INPUT_LENGTH, PREDICTION_LENGTH)\n","\n","# Print dataset distributions\n","print('Train set encompasses {:.1f}% of data'.format(100 * y_train.shape[0] / len(df)))\n","print('Validation set encompasses {:.1f}% of data'.format(100 * y_val.shape[0] / len(df)))\n","print('Test set encompasses {:.1f}% of data'.format(100 * y_test.shape[0] / len(df)))\n"],"metadata":{"id":"13YgJaUuNBtC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train.shape)\n","print(y_train.shape)"],"metadata":{"id":"n1ppsbnNVu51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# build TSMixer model\n","\n","def mixer_layer(inputs, ff_dim, activation = 'relu', dropout=0.7):\n","\n","  norm = layers.BatchNormalization\n","\n","  # Time mixing\n","  x = norm(axis=[-2, -1])(inputs)\n","  x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n","  x = layers.Dense(x.shape[-1], activation=activation)(x)\n","  x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Input Length, Channel]\n","  x = layers.Dropout(dropout)(x)\n","  res = x + inputs\n","\n","  # Feature mixing\n","  x = norm(axis=[-2, -1])(res)\n","  x = layers.Dense(ff_dim, activation=activation)(x)  # [Batch, Input Length, FF_Dim]\n","  x = layers.Dropout(dropout)(x)\n","  x = layers.Dense(inputs.shape[-1])(x)  # [Batch, Input Length, Channel]\n","  x = layers.Dropout(dropout)(x)\n","  return x + res\n","\n","\n","n_block = 8\n","ff_dim = 64\n","activation = 'relu'\n","dropout = 0.7\n","pred_len = 24\n","\n","inputs = tf.keras.Input(shape=X_train[0].shape)\n","\n","\n","# Residual blocks repetition\n","x = inputs  # [Batch, Input Length, Channel]\n","for _ in range(n_block):\n","  x = mixer_layer(x, ff_dim, activation, dropout)\n","\n","# Temporal projection\n","x = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Channel, Input Length]\n","x = layers.Dense(pred_len)(x)  # [Batch, Channel, Output Length]\n","outputs = tf.transpose(x, perm=[0, 2, 1])  # [Batch, Output Length, Channel])\n","\n","# Output\n","outputs = layers.Dense(1, activation='linear')(outputs)\n","\n","\n","model = tf.keras.Model(inputs, outputs)\n","model.compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),metrics = ['mae'])\n","model.summary()"],"metadata":{"id":"esbgW9XiOYKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train and validate tsmixer\n","\n","history = model.fit(X_train, y_train,\n","                    validation_data = (X_val, y_val),\n","                    epochs= 500,\n","                    batch_size = 32,\n","                    callbacks = tf.keras.callbacks.EarlyStopping(patience = 20,\n","                                                                 monitor = 'val_loss',\n","                                                                 restore_best_weights = True\n","                                                                )\n","                       )\n","\n","\n","history_df = pd.DataFrame(history.history)"],"metadata":{"id":"GBFAvdIXRCLu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.evaluate(X_train,y_train)\n","model.evaluate(X_val,y_val)\n","model.evaluate(X_test,y_test)"],"metadata":{"id":"eGXj0k6rRCRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = model.predict(X_test)"],"metadata":{"id":"V6MUVNS_OYSh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds.shape"],"metadata":{"id":"Jur04qOhUnSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot some predictions\n","\n","fig,axs = plt.subplots(5,5, figsize = (10,8))\n","axs = axs.ravel()\n","\n","for i in range(len(axs)):\n","    ax = axs[i]\n","    idx = random.randint(0, len(preds))\n","\n","    pred_series = preds[idx,:,:] * norm_stds['Temperature'] + norm_means['Temperature']\n","    true_series = y_test[idx,:,:] * norm_stds['Temperature'] + norm_means['Temperature']\n","    ax.plot(pred_series, color = 'red', label = 'prediction')\n","    ax.plot(true_series, color = 'black', label = 'true')\n","    ax.set_title('mae: {:.3f}'.format(np.mean(np.abs(pred_series - true_series))))\n","ax.legend(loc = (1,0))\n","\n","\n","fig.suptitle('Temperature predictions examples')\n","fig.tight_layout()"],"metadata":{"id":"72JsmJeySAxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot some results\n","\n","fig,ax = plt.subplots(1, figsize = (6,4))\n","ax.set_aspect(1)\n","x = y_test.reshape(-1)*norm_stds['Temperature'] + norm_means['Temperature']\n","y = preds.reshape(-1)*norm_stds['Temperature'] + norm_means['Temperature']\n","sns.regplot(x = x, y = y, ax=ax, truncate=False, color=\"#007aff\")\n","ax.set_xlabel('Temperature')\n","ax.set_ylabel('Prediction')\n","R2 = linregress(x,y).rvalue ** 2\n","ax.text(0.1, 0.95, f\"$R^2 = {R2:.2f}$\", fontsize=14, transform=ax.transAxes, va=\"top\", ha=\"left\")\n","fig.tight_layout()"],"metadata":{"id":"h05eSpgAOWs4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_lenght = 72\n","prediction_lenght = 24\n","\n","fig,ax = plt.subplots(1,1, figsize = (12,7))\n","\n","\n","datalist_dict_preds = []\n","datalist_dict_base_last_day = []\n","datalist_dict_avg_3days = []\n","\n","for idx in range(len(preds)):\n","  pred_series = preds[idx,:,0] * norm_stds['Temperature'] + norm_means['Temperature']\n","  true_series = y_test[idx,:,0] * norm_stds['Temperature'] + norm_means['Temperature']\n","  error = np.abs(pred_series - true_series)\n","\n","  for time, value in enumerate(error):\n","    data_dict_preds = {\n","        'time':time,\n","        'Temperature': value}\n","    datalist_dict_preds.append(data_dict_preds)\n","\n","\n","data = df_test['Temperature'].values* norm_stds['Temperature'] + norm_means['Temperature']\n","\n","for time_idx in range( len(df_test) - input_lenght - prediction_lenght ):\n","  baseline_1 = data[time_idx+input_lenght-prediction_lenght:time_idx+input_lenght]\n","  baseline_2 = data[time_idx+prediction_lenght:time_idx+input_lenght-prediction_lenght]\n","  baseline_3 = data[time_idx:time_idx+prediction_lenght]\n","\n","  baseline_last_day = baseline_1\n","  baseline_3days = np.mean(np.array([baseline_1, baseline_2, baseline_3]), axis = 0)\n","  target = data[time_idx+input_lenght : time_idx+input_lenght+prediction_lenght]\n","\n","  base_error_last_day = np.abs(baseline_last_day-target)\n","  for time, value in enumerate(base_error_last_day):\n","    data_dict_base_last_day = {\n","        'time':time,\n","        'Temperature': value}\n","    datalist_dict_base_last_day.append(data_dict_base_last_day)\n","\n","\n","  base_error_3days = np.abs(baseline_3days-target)\n","  for time, value in enumerate(base_error_3days):\n","    data_dict_base_3days = {\n","        'time':time,\n","        'Temperature': value}\n","    datalist_dict_avg_3days.append(data_dict_base_3days)\n","\n","\n","\n","#ax = axs[feat_idx]\n","df_pred = pd.DataFrame(datalist_dict_preds)\n","df_base_last_day = pd.DataFrame(datalist_dict_base_last_day)\n","df_base_avg_3days = pd.DataFrame(datalist_dict_avg_3days)\n","\n","sns.lineplot(data = df_pred, x = 'time',y= 'Temperature', color = 'darkorange',ax=ax, label = 'TSMixer')\n","sns.lineplot(data = df_base_last_day, x = 'time',y= 'Temperature', color = 'deepskyblue',ax=ax, label = 'Baseline last day')\n","sns.lineplot(data = df_base_avg_3days, x = 'time',y= 'Temperature', color = 'limegreen',ax=ax, label = 'Baseline avg 3 days')\n","\n","fontsize = 16\n","ax.set_xlabel('Prediction time [Hours]', fontsize = fontsize)\n","ax.set_ylabel('Absolute error [Â°C]', fontsize = fontsize)\n","ax.set_title('Temperature', fontsize = fontsize+2)\n","\n","ax.tick_params(axis='both', which='both', labelsize=12)\n","ax.legend(fontsize = 12)\n","\n","\n","\n","#axs[-1].set_visible(False)\n","\n","fig.suptitle('Time evolution of absolute error on test set', fontsize = fontsize+5)\n","fig.tight_layout()"],"metadata":{"id":"3dlGV5WQSAzs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JJE5KnlhSA2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WAjtGXmwR60X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QDZv3K-YaaiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yPnqMRQ5Ubmi"},"execution_count":null,"outputs":[]}]}